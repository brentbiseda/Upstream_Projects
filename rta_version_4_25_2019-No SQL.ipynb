{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PVT import *\n",
    "from wellDistance import *\n",
    "from well import *\n",
    "from report import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.ticker as mtick\n",
    "import os\n",
    "import errno\n",
    "from fpdf import FPDF\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the Data with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create data with SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Select Particular Wells in the Formation we Choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedPlay = \"MARCELLUS\"\n",
    "selectedPlay2 = \"Marcellus\"\n",
    "\n",
    "df = df[df.PLAY == selectedPlay]\n",
    "df2 = df2[df2.PLAY == selectedPlay2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectedPlay = \"UTICA\"\n",
    "# selectedPlay2 = \"Utica\"\n",
    "\n",
    "# df = df[df.PLAY == selectedPlay]\n",
    "# df2 = df2[df2.PLAY == selectedPlay2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize the Data as Binary pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('df.pkl')\n",
    "df2.to_pickle('df2.pkl')\n",
    "df3.to_pickle('df3.pkl')\n",
    "df4.to_pickle('df4.pkl')\n",
    "df5.to_pickle('df5.pkl')\n",
    "reservoirDF.to_pickle('reservoirDF.pkl')\n",
    "gasAnalysisDF.to_pickle('gasAnalysisDF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Binary Pkl Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pkl')\n",
    "df2 = pd.read_pickle('df2.pkl')\n",
    "df3 = pd.read_pickle('df3.pkl')\n",
    "df4 = pd.read_pickle('df4.pkl')\n",
    "df5 = pd.read_pickle('df5.pkl')\n",
    "reservoirDF = pd.read_pickle('reservoirDF.pkl')\n",
    "gasAnalysisDF = pd.read_pickle('gasAnalysisDF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data & Impute Nearest Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate the Heel of the wellbores\n",
    "heel_lat_list = []\n",
    "heel_lon_list = []\n",
    "\n",
    "for row in df2.iterrows():\n",
    "    heel_lat, heel_lon = get_heel(row)\n",
    "    heel_lat_list.append(heel_lat)\n",
    "    heel_lon_list.append(heel_lon)\n",
    "\n",
    "df2['heel_lat'] = heel_lat_list\n",
    "df2['heel_lon'] = heel_lon_list\n",
    "\n",
    "#Calculate the Midpoint of the wellbores\n",
    "mid_lat_list = []\n",
    "mid_lon_list = []\n",
    "\n",
    "for row in df2.iterrows():\n",
    "    mid_lat, mid_lon = get_midpoint(row)\n",
    "    mid_lat_list.append(mid_lat)\n",
    "    mid_lon_list.append(mid_lon)\n",
    "\n",
    "df2['mid_lat'] = mid_lat_list\n",
    "df2['mid_lon'] = mid_lon_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize completion dataframe\n",
    "df4 = df4.groupby('WELLID').agg({\n",
    "    'STAGE': 'max',\n",
    "    'FLUID_TOT': 'sum',\n",
    "    'FRESH_VOLUME': 'sum',\n",
    "    'TOTAL_SAND': 'sum',\n",
    "    'PERF_CLUSTERS_CNT': 'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summarize geology dataframe\n",
    "df5 = df5.groupby('WELLID').agg({\n",
    "    'TVD_AVG': 'mean',\n",
    "    'PEF_AVG': 'mean',\n",
    "    'GASFILLEDPHI_AVG': 'mean',\n",
    "    'SUWI_AVG': 'mean',\n",
    "    'WSM1_AVG': 'mean'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exclude the days prior to production\n",
    "df = df[~pd.isna(df['PRODUCTION_DAY_GAS_COUNTER'])]\n",
    "#Remove all zero producing days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Impute All the Values\n",
    "\n",
    "#We will Make use of the Fekete Harmony Datasets\n",
    "df2 = pd.merge(df2, reservoirDF, how='left', left_on=['WELLID'], right_on=['WELL_KEY'])\n",
    "\n",
    "#Impute Reservoir DF Values\n",
    "df2['POROSITY'] = FillValues(df2, 'POROSITY')\n",
    "df2['INITIAL_GAS_SATURATION'] = FillValues(df2, 'INITIAL_GAS_SATURATION')\n",
    "df2['INITIAL_RESERVOIR_PRESSURE'] = FillValues(df2, 'INITIAL_RESERVOIR_PRESSURE')\n",
    "df2['FORMATION_TEMPERATURE'] = FillValues(df2, 'FORMATION_TEMPERATURE')\n",
    "df2['INITIAL_WATER_SATURATION'] = FillValues(df2, 'INITIAL_WATER_SATURATION')\n",
    "df2['INITIAL_OIL_SATURATION'] = FillValues(df2, 'INITIAL_OIL_SATURATION')\n",
    "df2['INITIAL_OIL_SATURATION'] = FillValues(df2, 'INITIAL_OIL_SATURATION')\n",
    "\n",
    "#Gas Analysis DF\n",
    "gasAnalysisDF = gasAnalysisDF[['WELL_KEY', 'DATE_TIME', 'GAS_GRAVITY', 'N2', 'CO2', 'H2S', 'C1', 'C2', 'C3']]\n",
    "df2 = pd.merge(df2, gasAnalysisDF, how='left', left_on=['WELLID'], right_on=['WELL_KEY'])\n",
    "\n",
    "#Impute Gas Analysis DF Values\n",
    "df2['GAS_GRAVITY'] = FillValues(df2, 'GAS_GRAVITY')\n",
    "df2['N2'] = FillValues(df2, 'N2')\n",
    "df2['CO2'] = FillValues(df2, 'CO2')\n",
    "df2['H2S'] = FillValues(df2, 'H2S')\n",
    "df2['C1'] = FillValues(df2, 'C1')\n",
    "df2['C2'] = FillValues(df2, 'C2')\n",
    "df2['C3'] = FillValues(df2, 'C3')\n",
    "\n",
    "#Well Inputs Need to be imputed for gradient\n",
    "\n",
    "df2 = pd.merge(df2, df3, how='left', left_on=['WELLID'], right_on=['WELLID'])\n",
    "df2['GRADIENT'] = FillValues(df2, 'GRADIENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['CASING_PRESSURE_AVG'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('df.pkl')\n",
    "df2.to_pickle('df2.pkl')\n",
    "df3.to_pickle('df3.pkl')\n",
    "df4.to_pickle('df4.pkl')\n",
    "df5.to_pickle('df5.pkl')\n",
    "reservoirDF.to_pickle('reservoirDF.pkl')\n",
    "gasAnalysisDF.to_pickle('gasAnalysisDF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RTA Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Serialized & Pre-processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pkl')\n",
    "df2 = pd.read_pickle('df2.pkl')\n",
    "df3 = pd.read_pickle('df3.pkl')\n",
    "df4 = pd.read_pickle('df4.pkl')\n",
    "df5 = pd.read_pickle('df5.pkl')\n",
    "reservoirDF = pd.read_pickle('reservoirDF.pkl')\n",
    "gasAnalysisDF = pd.read_pickle('gasAnalysisDF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Well List for Reports that We Want to Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellList = df['FILENUM'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Specific wells to exclude because of missing information\n",
    "#This was determined only by attempting to run through every well then evaluating the errors:\n",
    "excludeList = ['50543','50134', '53069']\n",
    "wellList = np.setdiff1d(wellList, excludeList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating well #:  0  of  454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bisedab\\Desktop\\square_root_time\\well.py:121: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  lintime = (t_n ** 0.5) * q_init / q_n\n",
      "C:\\Users\\bisedab\\Desktop\\square_root_time\\well.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dp2 = (nQ - Qc)\n",
      "C:\\Users\\bisedab\\Desktop\\square_root_time\\well.py:181: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dp1 = (Qc - pQ)\n",
      "C:\\Users\\bisedab\\Desktop\\square_root_time\\well.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dpdx = (dpdx1 * dx2 + dpdx2 * dx1) / (dx1 + dx2)\n",
      "C:\\Users\\bisedab\\Desktop\\square_root_time\\PVT.py:95: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  test = abs((rho - rhoold) / rho)\n",
      "C:\\Users\\bisedab\\Desktop\\square_root_time\\PVT.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  Z = 0.27 * pr / rho / tr\n",
      "C:\\Users\\bisedab\\Desktop\\square_root_time\\well.py:121: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lintime = (t_n ** 0.5) * q_init / q_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating well #:  10  of  454\n",
      "Creating well #:  20  of  454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bisedab\\Desktop\\square_root_time\\well.py:222: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  v_t = 1.593 * wellDict['surface_tension'] ** 0.25 * (dens_liq - dens_gas) ** 0.25 / dens_gas ** 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating well #:  30  of  454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bisedab\\Desktop\\square_root_time\\well.py:192: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  bourdetDerivative[i] = (1 / dpdx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating well #:  40  of  454\n",
      "Creating well #:  50  of  454\n",
      "Creating well #:  60  of  454\n",
      "Creating well #:  70  of  454\n",
      "Creating well #:  80  of  454\n",
      "Creating well #:  90  of  454\n",
      "Creating well #:  100  of  454\n",
      "Creating well #:  110  of  454\n",
      "Creating well #:  120  of  454\n",
      "Creating well #:  130  of  454\n",
      "Creating well #:  140  of  454\n",
      "Creating well #:  150  of  454\n",
      "Creating well #:  160  of  454\n",
      "Creating well #:  170  of  454\n",
      "Creating well #:  180  of  454\n",
      "Creating well #:  190  of  454\n",
      "Creating well #:  200  of  454\n",
      "Creating well #:  210  of  454\n",
      "Creating well #:  220  of  454\n",
      "Creating well #:  230  of  454\n",
      "Creating well #:  240  of  454\n",
      "Creating well #:  250  of  454\n",
      "Creating well #:  260  of  454\n",
      "Creating well #:  270  of  454\n",
      "Creating well #:  280  of  454\n",
      "Creating well #:  290  of  454\n",
      "Creating well #:  300  of  454\n",
      "Creating well #:  310  of  454\n",
      "Creating well #:  320  of  454\n",
      "Creating well #:  330  of  454\n",
      "Creating well #:  340  of  454\n",
      "Creating well #:  350  of  454\n",
      "Creating well #:  360  of  454\n",
      "Creating well #:  370  of  454\n",
      "Creating well #:  380  of  454\n",
      "Creating well #:  390  of  454\n",
      "Creating well #:  400  of  454\n",
      "Creating well #:  410  of  454\n",
      "Creating well #:  420  of  454\n",
      "Creating well #:  430  of  454\n",
      "Creating well #:  440  of  454\n",
      "Creating well #:  450  of  454\n"
     ]
    }
   ],
   "source": [
    "wells = []\n",
    "for i, well in enumerate(wellList):\n",
    "    if i % 10 == 0:\n",
    "        print(\"Creating well #: \", i, \" of \", len(wellList) - 1)\n",
    "    wells.append(Well(well, df, df2, df3, df4, df5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write pickle to file\n",
    "\n",
    "with open('marcellus_wells.pkl', 'wb') as f:\n",
    "    pickle.dump(wells, f)\n",
    "    \n",
    "# with open('utica_wells.pkl', 'wb') as f:\n",
    "#     pickle.dump(wells, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Serialized & Pre-processed wells rather than recomputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in our file\n",
    "\n",
    "with open('marcellus_wells.pkl', 'rb') as f:\n",
    "    wells = pickle.load(f)\n",
    "\n",
    "# with open('utica_wells.pkl', 'rb') as f:\n",
    "#     wells = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Each Well Dict and Write to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Information\n",
    "wellcsv = pd.DataFrame()\n",
    "\n",
    "for well in wells:\n",
    "    wellDict = well.wellDict\n",
    "    wellDict = pd.Series(well.wellDict).to_frame().T\n",
    "    wellcsv = wellcsv.append(wellDict, ignore_index = False)\n",
    "    \n",
    "#Write to CSV\n",
    "# wellcsv.to_csv('utica.csv')\n",
    "wellcsv.to_csv('marcellus.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate All PDFs & Reporting Graphs & Extract calculated Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "myReport = Report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "for i, well in enumerate(wells):\n",
    "    if i % 10 == 0:\n",
    "        print(\"Creating Report #: \", i, \" of \", len(wells) - 1)\n",
    "    myReport.GeneratePlots(well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
